{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/remote/idiap.svm/project.evolang/meerkats_imen/evolang_meerkats_calls_classification/workspace/Notebooks-others\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "sys.path.insert(1,\"../\")\n",
    "print(os.getcwd())\n",
    "from src.models.Palazcnn import PalazCNN\n",
    "from src.models.lit import Lit\n",
    "from src.data.nccrmeerkatsdataset import NCCRMeerkatsDataset\n",
    "from src.data.isabelmeerkatdataset import isabelMerkatDataset\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import pandas as pd\n",
    "from src.utils import utils\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR=\"/idiap/project/evolang/meerkats_imen/evolang_meerkats_calls_classification/experiments/\" #dir for checkpoints\n",
    "DATA_DIR=\"/idiap/project/evolang/meerkats_imen/dataset/isabel_data/info_file.csv\" # to change depend on data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract last layer of best cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 476 data points in the test set \n",
      "There are 1905 data points in the train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/idiap/home/ibmahmoud/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.34437376  4.29572678 ...  0.4910565  13.81079292\n",
      "   2.        ]\n",
      " [ 0.          0.04206668  0.27667645 ...  0.27937749  0.71499008\n",
      "   5.        ]\n",
      " [ 0.          0.45979637  0.30111942 ...  0.15423302  3.19676852\n",
      "   2.        ]\n",
      " ...\n",
      " [ 0.          0.35824788  0.09588763 ...  0.15609115  0.9584164\n",
      "   1.        ]\n",
      " [ 0.          2.4225142   0.83061194 ...  1.16252112  5.30768347\n",
      "   2.        ]\n",
      " [ 0.          0.40227491  0.05811814 ...  0.37099299  1.23499727\n",
      "   2.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lit=Lit(model=PalazCNN(n_input=1,n_output=6),num_classes=6,learning_rate=0.003)\n",
    "\n",
    "checkpoint=torch.load(MAIN_DIR + \"experiment_3/checkpoints/epoch=99-step=9600-v1.ckpt\",map_location=torch.device('cpu')) #best marta model\n",
    "lit.load_state_dict(checkpoint[\"state_dict\"])\n",
    "lit.model.eval()\n",
    "with open('../src/data/class_to_index_isabel.json') as f:\n",
    "        class_to_index = json.load(f)\n",
    "data_test = isabelMerkatDataset(\n",
    "            audio_dir=DATA_DIR,\n",
    "            class_to_index=class_to_index,\n",
    "            target_sample_rate=16000,\n",
    "            train=False) \n",
    "   \n",
    "    \n",
    "data_train = isabelMerkatDataset(\n",
    "        audio_dir=DATA_DIR,\n",
    "        class_to_index=class_to_index,\n",
    "        target_sample_rate=16000,\n",
    "        train=True) \n",
    "result={}\n",
    "k_folds=5\n",
    "dataset=torch.utils.data.ConcatDataset([data_test,data_train])\n",
    "labels=dataset.datasets[0].filelist.class_index.tolist()+ dataset.datasets[1].filelist.class_index.tolist()\n",
    "kfold=StratifiedKFold(n_splits=k_folds,shuffle=True,random_state=42)\n",
    "\n",
    "accuracies_folds=[]\n",
    "\n",
    "for fold,(train_ids,test_ids) in enumerate(kfold.split(dataset,labels)):\n",
    "        if fold==1:\n",
    "                \n",
    "                num_train = len(train_ids)\n",
    "                split = int(np.floor(0.2* num_train))\n",
    "                                        #numpy.random.shuffle(indices)\n",
    "\n",
    "                                        # mask=dataset.filelist.index.isin(train_ids)\n",
    "                                        # dataset_=dataset.filelist[mask] \n",
    "                                        # all_ids=numpy.arange(0,len(dataset))\n",
    "                                        # mask=x.index.isin(train_ids)\n",
    "                                        # dataset_=x[mask]\n",
    "                                        # for k, (train_idx, valid_idx) in enumerate(kfold.split(dataset_,dataset_.class_index)):\n",
    "                                        #         train_ids=train_idx\n",
    "                                        #         break\n",
    "                                        # all_ids=numpy.arange(0,len(dataset))\n",
    "                                        # keep_mask=numpy.isin(all_ids,test_ids,invert=True)\n",
    "                                        # new_ids=all_ids[keep_mask]\n",
    "                                        # train_ids=new_ids[train_ids]\n",
    "                                        # valid_idx=new_ids[valid_idx]\n",
    "                print(f'There are {len(test_ids)} data points in the test set ')\n",
    "                print(f'There are {len(train_ids)} data points in the train set') \n",
    "                train_subsampler=torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "                test_subsampler=torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "                                # Dataloader in this fold\n",
    "                train_loader = DataLoader(dataset, batch_size=1,sampler=train_subsampler,collate_fn=utils.collate_fn, num_workers=4)\n",
    "                test_loader = DataLoader(dataset, batch_size=1,sampler=test_subsampler, shuffle=False,collate_fn=utils.collate_fn, num_workers=4)\n",
    "\n",
    "                FEATS=[] # list of all the features\n",
    "                for batch in iter(test_loader):\n",
    "                        input,labels=batch\n",
    "                # forward pass [with feature extraction]\n",
    "                        x,intermediate=lit.model(input)\n",
    "                        output=np.c_[intermediate.detach().numpy(),labels.detach().numpy()]\n",
    "                        FEATS.append(output)\n",
    "                        \n",
    "                FEATS_test=np.array(FEATS)\n",
    "                FEATS_test=FEATS_test.reshape((FEATS_test.shape[0]*FEATS_test.shape[1]), FEATS_test.shape[2]) # final features numpy\n",
    "                FEATS=[]\n",
    "                for batch in iter(train_loader):\n",
    "                        input,labels=batch\n",
    "                # forward pass [with feature extraction]\n",
    "                        x,intermediate=lit.model(input)\n",
    "                        output=np.c_[intermediate.detach().numpy(),labels.detach().numpy()]\n",
    "                        FEATS.append(output)\n",
    "                        \n",
    "                FEATS_train=np.array(FEATS)\n",
    "                print(FEATS_train[:,-1])\n",
    "                FEATS_train=FEATS_train.reshape((FEATS_train.shape[0]*FEATS_train.shape[1]), FEATS_train.shape[2]) # final features numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [0,10,20,30,40,50, 70,80, 100, 150, 200],\n",
    "    \"max_depth\": [None, 5, 7 , 10],\n",
    "    \"min_samples_split\": [2, 3,5, 7,10],\n",
    "    \"min_samples_leaf\": [1, 2, 3,4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test=FEATS_test[:,:-1]\n",
    "labels_test=FEATS_test[:,-1]\n",
    "features_train=FEATS_train[:,:-1]\n",
    "labels_train=FEATS_train[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(476, 81)\n",
      "[2. 5. 2. ... 1. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(FEATS_test.shape)\n",
    "print(labels_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/idiap/temp/ibmahmoud/miniconda3/envs/s3prl-pytorch/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "400 fits failed out of a total of 4400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/idiap/temp/ibmahmoud/miniconda3/envs/s3prl-pytorch/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/idiap/temp/ibmahmoud/miniconda3/envs/s3prl-pytorch/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
      "    self._validate_params()\n",
      "  File \"/idiap/temp/ibmahmoud/miniconda3/envs/s3prl-pytorch/lib/python3.9/site-packages/sklearn/base.py\", line 581, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/idiap/temp/ibmahmoud/miniconda3/envs/s3prl-pytorch/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_estimators' parameter of RandomForestClassifier must be an int in the range [1, inf). Got 0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/idiap/temp/ibmahmoud/miniconda3/envs/s3prl-pytorch/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.72388451 0.74068241 0.75380577 0.7496063  0.75328084\n",
      " 0.75538058 0.75958005 0.76062992 0.76377953 0.76272966        nan\n",
      " 0.74855643 0.75853018 0.75958005 0.76167979 0.76115486 0.76220472\n",
      " 0.76272966 0.76535433 0.76902887 0.76430446        nan 0.74330709\n",
      " 0.75170604 0.76167979 0.76325459 0.76167979 0.76692913 0.76745407\n",
      " 0.76430446 0.76587927 0.76535433        nan 0.74278215 0.74750656\n",
      " 0.75485564 0.76010499 0.7664042  0.76535433 0.76115486 0.76377953\n",
      " 0.76167979 0.76115486        nan 0.74278215 0.75590551 0.75275591\n",
      " 0.76115486 0.76220472 0.76010499 0.76430446 0.76010499 0.76220472\n",
      " 0.76535433        nan 0.74645669 0.75590551 0.75590551 0.76115486\n",
      " 0.7648294  0.76325459 0.76955381 0.76587927 0.76272966 0.76167979\n",
      "        nan 0.74645669 0.75590551 0.75590551 0.76115486 0.7648294\n",
      " 0.76325459 0.76955381 0.76587927 0.76272966 0.76167979        nan\n",
      " 0.73648294 0.75328084 0.75065617 0.75380577 0.75485564 0.75328084\n",
      " 0.75590551 0.75590551 0.75905512 0.75485564        nan 0.7328084\n",
      " 0.7496063  0.75485564 0.76062992 0.75695538 0.76377953 0.76220472\n",
      " 0.767979   0.76850394 0.76745407        nan 0.73753281 0.74278215\n",
      " 0.75223097 0.75223097 0.75433071 0.75380577 0.75433071 0.75643045\n",
      " 0.76010499 0.76010499        nan 0.74383202 0.75223097 0.75958005\n",
      " 0.76325459 0.76272966 0.76115486 0.76167979 0.76272966 0.76115486\n",
      " 0.76115486        nan 0.74383202 0.75223097 0.75958005 0.76325459\n",
      " 0.76272966 0.76115486 0.76167979 0.76272966 0.76115486 0.76115486\n",
      "        nan 0.74383202 0.75223097 0.75958005 0.76325459 0.76272966\n",
      " 0.76115486 0.76167979 0.76272966 0.76115486 0.76115486        nan\n",
      " 0.74330709 0.75485564 0.75590551 0.76167979 0.76430446 0.76010499\n",
      " 0.76220472 0.7648294  0.76272966 0.76377953        nan 0.73858268\n",
      " 0.75223097 0.75958005 0.76167979 0.76115486 0.76325459 0.7664042\n",
      " 0.76745407 0.76220472 0.76062992        nan 0.74435696 0.75748031\n",
      " 0.75958005 0.76325459 0.7648294  0.76377953 0.76430446 0.76062992\n",
      " 0.75853018 0.76325459        nan 0.74435696 0.75748031 0.75958005\n",
      " 0.76325459 0.7648294  0.76377953 0.76430446 0.76062992 0.75853018\n",
      " 0.76325459        nan 0.74435696 0.75748031 0.75958005 0.76325459\n",
      " 0.7648294  0.76377953 0.76430446 0.76062992 0.75853018 0.76325459\n",
      "        nan 0.74435696 0.75748031 0.75958005 0.76325459 0.7648294\n",
      " 0.76377953 0.76430446 0.76062992 0.75853018 0.76325459        nan\n",
      " 0.73858268 0.75275591 0.75275591 0.75748031 0.75800525 0.75380577\n",
      " 0.75695538 0.75643045 0.75748031 0.76167979        nan 0.72860892\n",
      " 0.7312336  0.73070866 0.73333333 0.73333333 0.73753281 0.73490814\n",
      " 0.73648294 0.7343832  0.73543307        nan 0.72965879 0.73175853\n",
      " 0.73175853 0.7312336  0.73595801 0.7343832  0.72808399 0.73595801\n",
      " 0.7328084  0.73595801        nan 0.72650919 0.73543307 0.72703412\n",
      " 0.73595801 0.73490814 0.73333333 0.73595801 0.73595801 0.73490814\n",
      " 0.73543307        nan 0.72913386 0.73490814 0.73333333 0.73648294\n",
      " 0.73858268 0.7328084  0.7343832  0.73753281 0.73648294 0.73700787\n",
      "        nan 0.73333333 0.73858268 0.74225722 0.74330709 0.73805774\n",
      " 0.73385827 0.73753281 0.73595801 0.73385827 0.73490814        nan\n",
      " 0.73175853 0.7343832  0.72913386 0.7328084  0.73385827 0.73333333\n",
      " 0.7328084  0.73595801 0.73490814 0.73648294        nan 0.73175853\n",
      " 0.7343832  0.72913386 0.7328084  0.73385827 0.73333333 0.7328084\n",
      " 0.73595801 0.73490814 0.73648294        nan 0.72913386 0.73385827\n",
      " 0.72808399 0.73700787 0.7343832  0.73490814 0.73228346 0.73648294\n",
      " 0.73543307 0.73543307        nan 0.73018373 0.7343832  0.73333333\n",
      " 0.73648294 0.73910761 0.73385827 0.73175853 0.73595801 0.73648294\n",
      " 0.73753281        nan 0.73595801 0.73490814 0.74120735 0.74015748\n",
      " 0.74015748 0.73595801 0.73595801 0.7343832  0.73228346 0.7343832\n",
      "        nan 0.73070866 0.73228346 0.7312336  0.7312336  0.73700787\n",
      " 0.73228346 0.7328084  0.73700787 0.73490814 0.73595801        nan\n",
      " 0.73070866 0.73228346 0.7312336  0.7312336  0.73700787 0.73228346\n",
      " 0.7328084  0.73700787 0.73490814 0.73595801        nan 0.73070866\n",
      " 0.73228346 0.7312336  0.7312336  0.73700787 0.73228346 0.7328084\n",
      " 0.73700787 0.73490814 0.73595801        nan 0.72755906 0.73333333\n",
      " 0.73385827 0.73490814 0.7343832  0.73333333 0.73333333 0.73753281\n",
      " 0.73385827 0.73648294        nan 0.7343832  0.73805774 0.74015748\n",
      " 0.74278215 0.73858268 0.73490814 0.73595801 0.73648294 0.7328084\n",
      " 0.7328084         nan 0.7312336  0.73543307 0.73700787 0.74015748\n",
      " 0.73753281 0.73753281 0.73700787 0.73805774 0.73805774 0.73753281\n",
      "        nan 0.7312336  0.73543307 0.73700787 0.74015748 0.73753281\n",
      " 0.73753281 0.73700787 0.73805774 0.73805774 0.73753281        nan\n",
      " 0.7312336  0.73543307 0.73700787 0.74015748 0.73753281 0.73753281\n",
      " 0.73700787 0.73805774 0.73805774 0.73753281        nan 0.7312336\n",
      " 0.73543307 0.73700787 0.74015748 0.73753281 0.73753281 0.73700787\n",
      " 0.73805774 0.73805774 0.73753281        nan 0.73385827 0.73490814\n",
      " 0.74068241 0.74225722 0.73753281 0.73490814 0.73543307 0.73595801\n",
      " 0.7312336  0.7343832         nan 0.74015748 0.74383202 0.74330709\n",
      " 0.7480315  0.75013123 0.75013123 0.75013123 0.7511811  0.75170604\n",
      " 0.75170604        nan 0.74593176 0.75380577 0.75013123 0.75328084\n",
      " 0.75275591 0.74855643 0.75013123 0.75170604 0.75013123 0.75013123\n",
      "        nan 0.73490814 0.73700787 0.74698163 0.75223097 0.74645669\n",
      " 0.74698163 0.7496063  0.7511811  0.75275591 0.75223097        nan\n",
      " 0.75065617 0.74855643 0.75013123 0.74908136 0.74855643 0.74855643\n",
      " 0.75013123 0.75065617 0.75170604 0.75013123        nan 0.74225722\n",
      " 0.75013123 0.74698163 0.74855643 0.74593176 0.75275591 0.75328084\n",
      " 0.75013123 0.75433071 0.75328084        nan 0.73963255 0.75170604\n",
      " 0.75013123 0.75275591 0.7511811  0.75170604 0.75170604 0.75013123\n",
      " 0.7496063  0.7511811         nan 0.73963255 0.75170604 0.75013123\n",
      " 0.75275591 0.7511811  0.75170604 0.75170604 0.75013123 0.7496063\n",
      " 0.7511811         nan 0.74330709 0.74645669 0.7511811  0.75170604\n",
      " 0.75328084 0.7496063  0.7496063  0.75013123 0.75170604 0.75328084\n",
      "        nan 0.74488189 0.74383202 0.74435696 0.75013123 0.74855643\n",
      " 0.75275591 0.75433071 0.75433071 0.75223097 0.75223097        nan\n",
      " 0.74488189 0.75065617 0.74855643 0.75013123 0.74540682 0.75065617\n",
      " 0.7511811  0.74855643 0.7496063  0.75065617        nan 0.74383202\n",
      " 0.75590551 0.74855643 0.75275591 0.75590551 0.75590551 0.75433071\n",
      " 0.75275591 0.75223097 0.7511811         nan 0.74383202 0.75590551\n",
      " 0.74855643 0.75275591 0.75590551 0.75590551 0.75433071 0.75275591\n",
      " 0.75223097 0.7511811         nan 0.74383202 0.75590551 0.74855643\n",
      " 0.75275591 0.75590551 0.75590551 0.75433071 0.75275591 0.75223097\n",
      " 0.7511811         nan 0.73963255 0.74645669 0.7480315  0.7480315\n",
      " 0.74645669 0.75013123 0.75433071 0.7511811  0.74855643 0.74855643\n",
      "        nan 0.74225722 0.75013123 0.75013123 0.75433071 0.75065617\n",
      " 0.74855643 0.75328084 0.75328084 0.75275591 0.75065617        nan\n",
      " 0.74278215 0.75013123 0.74908136 0.74908136 0.7511811  0.75223097\n",
      " 0.7496063  0.75065617 0.7511811  0.75170604        nan 0.74278215\n",
      " 0.75013123 0.74908136 0.74908136 0.7511811  0.75223097 0.7496063\n",
      " 0.75065617 0.7511811  0.75170604        nan 0.74278215 0.75013123\n",
      " 0.74908136 0.74908136 0.7511811  0.75223097 0.7496063  0.75065617\n",
      " 0.7511811  0.75170604        nan 0.74278215 0.75013123 0.74908136\n",
      " 0.74908136 0.7511811  0.75223097 0.7496063  0.75065617 0.7511811\n",
      " 0.75170604        nan 0.74435696 0.74645669 0.74435696 0.7511811\n",
      " 0.75170604 0.74698163 0.7496063  0.7496063  0.7480315  0.7511811\n",
      "        nan 0.73228346 0.75328084 0.75433071 0.75485564 0.75275591\n",
      " 0.75800525 0.75905512 0.76167979 0.76220472 0.76010499        nan\n",
      " 0.74750656 0.75170604 0.75958005 0.75695538 0.75643045 0.76272966\n",
      " 0.75958005 0.7648294  0.76377953 0.76220472        nan 0.74540682\n",
      " 0.75065617 0.74855643 0.75380577 0.75853018 0.76167979 0.76010499\n",
      " 0.75905512 0.76062992 0.76010499        nan 0.73648294 0.74330709\n",
      " 0.75013123 0.7511811  0.75275591 0.75538058 0.75905512 0.76062992\n",
      " 0.75590551 0.75853018        nan 0.73963255 0.75485564 0.75170604\n",
      " 0.75328084 0.75485564 0.75748031 0.75590551 0.75643045 0.76062992\n",
      " 0.75853018        nan 0.73648294 0.74120735 0.74750656 0.7480315\n",
      " 0.75170604 0.75328084 0.75590551 0.75538058 0.75853018 0.75748031\n",
      "        nan 0.73648294 0.74120735 0.74750656 0.7480315  0.75170604\n",
      " 0.75328084 0.75590551 0.75538058 0.75853018 0.75748031        nan\n",
      " 0.75013123 0.75485564 0.75433071 0.75958005 0.76062992 0.76272966\n",
      " 0.76062992 0.76167979 0.76272966 0.75853018        nan 0.74068241\n",
      " 0.74855643 0.75380577 0.75800525 0.75485564 0.75590551 0.75643045\n",
      " 0.75958005 0.76010499 0.75800525        nan 0.74015748 0.7496063\n",
      " 0.75590551 0.75380577 0.75380577 0.75538058 0.75433071 0.75590551\n",
      " 0.75800525 0.75748031        nan 0.74908136 0.75065617 0.75748031\n",
      " 0.76010499 0.76430446 0.76377953 0.76220472 0.7664042  0.76377953\n",
      " 0.76167979        nan 0.74908136 0.75065617 0.75748031 0.76010499\n",
      " 0.76430446 0.76377953 0.76220472 0.7664042  0.76377953 0.76167979\n",
      "        nan 0.74908136 0.75065617 0.75748031 0.76010499 0.76430446\n",
      " 0.76377953 0.76220472 0.7664042  0.76377953 0.76167979        nan\n",
      " 0.73543307 0.74855643 0.75013123 0.75800525 0.75905512 0.76010499\n",
      " 0.75905512 0.76010499 0.75800525 0.75748031        nan 0.73963255\n",
      " 0.7496063  0.75223097 0.75748031 0.75643045 0.75748031 0.75590551\n",
      " 0.75853018 0.75485564 0.75590551        nan 0.7343832  0.7496063\n",
      " 0.75695538 0.76167979 0.76115486 0.76377953 0.76377953 0.7648294\n",
      " 0.76220472 0.76430446        nan 0.7343832  0.7496063  0.75695538\n",
      " 0.76167979 0.76115486 0.76377953 0.76377953 0.7648294  0.76220472\n",
      " 0.76430446        nan 0.7343832  0.7496063  0.75695538 0.76167979\n",
      " 0.76115486 0.76377953 0.76377953 0.7648294  0.76220472 0.76430446\n",
      "        nan 0.7343832  0.7496063  0.75695538 0.76167979 0.76115486\n",
      " 0.76377953 0.76377953 0.7648294  0.76220472 0.76430446        nan\n",
      " 0.74225722 0.75065617 0.75065617 0.75275591 0.75223097 0.75328084\n",
      " 0.75223097 0.75485564 0.74855643 0.75380577]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 5, 7, 10],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 5, 7, 10],\n",
       "                         &#x27;n_estimators&#x27;: [0, 10, 20, 30, 40, 50, 70, 80, 100,\n",
       "                                          150, 200]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 5, 7, 10],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 5, 7, 10],\n",
       "                         &#x27;n_estimators&#x27;: [0, 10, 20, 30, 40, 50, 70, 80, 100,\n",
       "                                          150, 200]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 5, 7, 10],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4],\n",
       "                         'min_samples_split': [2, 3, 5, 7, 10],\n",
       "                         'n_estimators': [0, 10, 20, 30, 40, 50, 70, 80, 100,\n",
       "                                          150, 200]})"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(features_train, labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=grid_search.best_estimator_\n",
    "y_pred=best_model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 5., 5., 2., 1., 2., 5., 5., 5., 2., 5., 2., 2., 2., 5., 1., 2.,\n",
       "       5., 2., 2., 2., 2., 2., 2., 2., 5., 5., 5., 2., 2., 2., 5., 2., 2.,\n",
       "       2., 2., 5., 5., 2., 2., 2., 5., 2., 5., 2., 5., 1., 2., 2., 5., 5.,\n",
       "       5., 2., 5., 2., 2., 5., 2., 5., 5., 5., 2., 2., 5., 1., 2., 2., 2.,\n",
       "       2., 5., 2., 1., 1., 2., 5., 5., 2., 5., 1., 5., 2., 2., 2., 2., 5.,\n",
       "       5., 2., 2., 5., 5., 2., 2., 5., 2., 2., 5., 2., 5., 2., 5., 5., 5.,\n",
       "       2., 5., 1., 2., 2., 5., 2., 2., 2., 2., 5., 2., 5., 5., 2., 5., 2.,\n",
       "       5., 2., 5., 1., 2., 2., 5., 2., 2., 5., 2., 5., 2., 2., 5., 2., 2.,\n",
       "       2., 2., 5., 2., 2., 2., 2., 2., 2., 5., 2., 5., 5., 5., 2., 2., 2.,\n",
       "       2., 2., 2., 5., 5., 5., 5., 2., 2., 2., 2., 1., 2., 2., 5., 5., 5.,\n",
       "       1., 5., 2., 5., 2., 1., 2., 2., 2., 5., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       5., 2., 2., 1., 1., 5., 5., 2., 5., 5., 2., 2., 2., 2., 2., 2., 5.,\n",
       "       2., 2., 5., 2., 2., 2., 2., 2., 5., 2., 5., 5., 2., 1., 2., 2., 5.,\n",
       "       2., 1., 2., 5., 2., 2., 2., 5., 1., 2., 5., 5., 2., 5., 2., 5., 2.,\n",
       "       2., 2., 2., 5., 2., 2., 5., 5., 2., 2., 5., 1., 2., 5., 5., 2., 2.,\n",
       "       5., 2., 2., 5., 5., 2., 5., 2., 5., 2., 2., 2., 2., 5., 5., 5., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 5., 5., 5., 2., 2., 2., 2., 5., 5., 2.,\n",
       "       2., 5., 2., 5., 2., 2., 2., 5., 5., 2., 2., 2., 2., 2., 2., 5., 5.,\n",
       "       5., 2., 5., 2., 5., 2., 2., 5., 2., 5., 5., 5., 2., 2., 2., 2., 2.,\n",
       "       2., 5., 2., 2., 5., 2., 5., 5., 1., 2., 5., 2., 2., 2., 5., 2., 5.,\n",
       "       5., 2., 5., 5., 5., 2., 2., 5., 2., 5., 2., 2., 5., 2., 5., 2., 2.,\n",
       "       2., 2., 2., 2., 5., 2., 2., 2., 5., 2., 2., 5., 5., 5., 2., 2., 2.,\n",
       "       2., 1., 2., 2., 2., 5., 2., 2., 5., 2., 2., 5., 2., 2., 2., 2., 2.,\n",
       "       2., 5., 2., 1., 2., 5., 2., 2., 2., 2., 5., 5., 1., 5., 1., 2., 2.,\n",
       "       2., 5., 2., 1., 5., 5., 5., 2., 2., 5., 5., 5., 5., 5., 1., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 2., 5., 5., 2., 2., 5., 2., 2., 2., 2., 5., 2.,\n",
       "       2., 2., 2., 2., 5., 2., 2., 2., 5., 2., 5., 5., 2., 2., 5., 5., 5.,\n",
       "       5., 5., 2., 2., 5., 2., 5., 2., 5., 2., 5., 2., 2., 5., 2., 2., 5.])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3., 5., 2., 1., 2., 5., 5., 5., 2., 2., 2., 2., 2., 5., 3., 5.,\n",
       "       5., 2., 5., 1., 5., 5., 2., 2., 2., 5., 2., 5., 2., 2., 5., 2., 3.,\n",
       "       2., 2., 5., 5., 2., 2., 2., 5., 2., 2., 5., 5., 1., 2., 2., 5., 5.,\n",
       "       2., 2., 2., 2., 5., 3., 2., 5., 5., 5., 2., 0., 5., 1., 2., 2., 5.,\n",
       "       1., 5., 2., 2., 1., 2., 5., 5., 5., 5., 1., 5., 2., 2., 2., 2., 2.,\n",
       "       2., 5., 2., 2., 2., 2., 2., 5., 2., 5., 2., 0., 2., 5., 2., 5., 2.,\n",
       "       0., 2., 1., 2., 2., 2., 0., 5., 2., 2., 5., 2., 5., 5., 2., 2., 2.,\n",
       "       5., 0., 5., 2., 2., 2., 2., 2., 2., 1., 2., 2., 2., 2., 5., 3., 2.,\n",
       "       1., 2., 2., 2., 2., 2., 2., 2., 5., 1., 5., 3., 2., 2., 5., 5., 1.,\n",
       "       2., 2., 2., 5., 1., 5., 3., 1., 2., 2., 2., 0., 2., 2., 5., 5., 5.,\n",
       "       1., 4., 2., 5., 2., 1., 2., 0., 2., 5., 2., 5., 5., 5., 0., 2., 2.,\n",
       "       2., 5., 2., 2., 5., 5., 5., 2., 5., 5., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 5., 2., 2., 5., 2., 5., 5., 5., 2., 5., 5., 5., 3., 1., 2., 1.,\n",
       "       2., 1., 2., 5., 5., 2., 2., 2., 1., 5., 5., 3., 0., 1., 0., 5., 2.,\n",
       "       2., 2., 2., 5., 2., 2., 2., 2., 5., 2., 5., 1., 2., 5., 1., 2., 2.,\n",
       "       1., 5., 5., 2., 5., 2., 5., 5., 5., 5., 5., 2., 2., 5., 5., 2., 5.,\n",
       "       2., 1., 2., 2., 5., 5., 2., 1., 2., 3., 2., 2., 5., 5., 5., 1., 2.,\n",
       "       2., 5., 5., 5., 2., 1., 5., 5., 5., 2., 2., 5., 2., 2., 2., 2., 5.,\n",
       "       2., 2., 3., 2., 5., 2., 2., 1., 2., 3., 2., 5., 2., 5., 1., 5., 1.,\n",
       "       2., 0., 2., 2., 5., 2., 5., 0., 5., 2., 5., 2., 2., 5., 5., 5., 5.,\n",
       "       2., 5., 3., 2., 5., 0., 2., 5., 2., 5., 2., 1., 5., 2., 5., 2., 2.,\n",
       "       2., 2., 0., 5., 5., 2., 2., 2., 5., 2., 5., 5., 2., 1., 2., 2., 2.,\n",
       "       2., 1., 2., 2., 5., 2., 2., 2., 5., 2., 2., 2., 2., 2., 0., 5., 2.,\n",
       "       5., 5., 2., 1., 5., 1., 5., 5., 2., 2., 5., 2., 1., 5., 1., 2., 5.,\n",
       "       2., 5., 5., 1., 5., 5., 5., 5., 2., 5., 2., 5., 5., 4., 2., 1., 5.,\n",
       "       2., 2., 0., 3., 2., 2., 5., 2., 2., 0., 5., 2., 0., 5., 4., 2., 2.,\n",
       "       2., 5., 5., 2., 5., 4., 2., 2., 5., 3., 5., 5., 5., 2., 5., 2., 5.,\n",
       "       1., 2., 2., 2., 1., 2., 1., 2., 5., 5., 1., 2., 2., 5., 2., 4., 5.])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,  14,   0,   0,   3],\n",
       "       [  0,  16,  11,   0,   0,  17],\n",
       "       [  0,   4, 177,   0,   0,  48],\n",
       "       [  0,   2,   3,   0,   0,  10],\n",
       "       [  0,   0,   3,   0,   0,   2],\n",
       "       [  0,   2,  63,   0,   0, 100]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion=metrics.confusion_matrix(labels_test,y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2904371223148516"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.diag(confusion) / np.sum(confusion,axis=1))/6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.3s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.7s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.5s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.6s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.1s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.2s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.6s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.5s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.6s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.2s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.2s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.2s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.2s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.2s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.2s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.2s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.2s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.8s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.7s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.9s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.7s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.6s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.5s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.5s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.6s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.8s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.7s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.9s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.7s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.6s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.3s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.9s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.7s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.9s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.7s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.6s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.8s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.7s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.9s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.7s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.6s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=  13.7s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   5.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   8.0s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   7.2s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   7.1s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.4s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.6s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.5s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.5s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.6s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=  13.8s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   5.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   8.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   7.2s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   7.1s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.6s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.5s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.4s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.5s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=  13.8s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   5.1s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   8.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   7.2s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   7.3s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.2s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=  14.2s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   5.2s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   8.2s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   7.2s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   7.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.1s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;poly&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['linear', 'rbf', 'poly', 'sigmoid']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['linear','rbf', 'poly', 'sigmoid']}\n",
    "grid=GridSearchCV(svm.SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(features_train,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,  11,   0,   0,   6],\n",
       "       [  0,  17,  11,   1,   0,  15],\n",
       "       [  2,   7, 165,   1,   1,  53],\n",
       "       [  0,   2,   2,   0,   0,  11],\n",
       "       [  0,   0,   3,   0,   0,   2],\n",
       "       [  3,  11,  55,   1,   0,  95]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_predictions = grid.predict(features_test)\n",
    "confusion_m=metrics.confusion_matrix(labels_test,grid_predictions)\n",
    "confusion_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28044087159807685"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.diag(confusion_m) / np.sum(confusion_m,axis=1))/6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s3prl-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
