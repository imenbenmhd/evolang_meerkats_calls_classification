2023-05-09 18:00:20,302 INFO gridtk: Starting job 51: /idiap/temp/esarkar/miniconda/envs/pytorch_vad/bin/python /idiap/project/evolang/meerkats_imen/evolang_meerkats_calls_classification/workspace/pretrainMara-marta.py -dir /idiap/project/evolang/meerkats_imen/dataset/isabel_data/info_file.csv -s 16000 -b 16 -lr 0.003
/idiap/temp/esarkar/miniconda/envs/pytorch_vad/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
wandb: Currently logged in as: imenbm. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.4
wandb: Run data is saved locally in ./wandb/run-20230509_180054-q7l0ain1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ADAM-pretrained-mara-on-isabel-fixingweights
wandb: ⭐️ View project at https://wandb.ai/imenbm/Isabel_meerkat
wandb: 🚀 View run at https://wandb.ai/imenbm/Isabel_meerkat/runs/q7l0ain1
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type     | Params
-----------------------------------
0 | model | PalazCNN | 23.0 K
-----------------------------------
486       Trainable params
22.6 K    Non-trainable params
23.0 K    Total params
0.092     Total estimated model params size (MB)
`Trainer.fit` stopped: `max_epochs=100` reached.
Restoring states from the checkpoint path at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600.ckpt
Restoring states from the checkpoint path at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/idiap/temp/esarkar/miniconda/envs/pytorch_vad/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory ./Isabel_meerkat/q7l0ain1/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type     | Params
-----------------------------------
0 | model | PalazCNN | 23.0 K
-----------------------------------
486       Trainable params
22.6 K    Non-trainable params
23.0 K    Total params
0.092     Total estimated model params size (MB)
`Trainer.fit` stopped: `max_epochs=100` reached.
Restoring states from the checkpoint path at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v1.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v1.ckpt
Restoring states from the checkpoint path at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v1.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v1.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/idiap/temp/esarkar/miniconda/envs/pytorch_vad/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory ./Isabel_meerkat/q7l0ain1/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type     | Params
-----------------------------------
0 | model | PalazCNN | 23.0 K
-----------------------------------
486       Trainable params
22.6 K    Non-trainable params
23.0 K    Total params
0.092     Total estimated model params size (MB)
`Trainer.fit` stopped: `max_epochs=100` reached.
Restoring states from the checkpoint path at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v2.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v2.ckpt
Restoring states from the checkpoint path at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v2.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v2.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/idiap/temp/esarkar/miniconda/envs/pytorch_vad/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory ./Isabel_meerkat/q7l0ain1/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type     | Params
-----------------------------------
0 | model | PalazCNN | 23.0 K
-----------------------------------
486       Trainable params
22.6 K    Non-trainable params
23.0 K    Total params
0.092     Total estimated model params size (MB)
`Trainer.fit` stopped: `max_epochs=100` reached.
Restoring states from the checkpoint path at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v3.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v3.ckpt
Restoring states from the checkpoint path at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v3.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v3.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/idiap/temp/esarkar/miniconda/envs/pytorch_vad/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory ./Isabel_meerkat/q7l0ain1/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type     | Params
-----------------------------------
0 | model | PalazCNN | 23.0 K
-----------------------------------
486       Trainable params
22.6 K    Non-trainable params
23.0 K    Total params
0.092     Total estimated model params size (MB)
`Trainer.fit` stopped: `max_epochs=100` reached.
Restoring states from the checkpoint path at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v4.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v4.ckpt
Restoring states from the checkpoint path at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v4.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Loaded model weights from checkpoint at ./Isabel_meerkat/q7l0ain1/checkpoints/epoch=99-step=9600-v4.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:               epoch ▁▂▃▄▅▆▇█▁▂▃▄▅▆▇█▁▂▃▄▅▆▇█▁▂▃▄▅▆▇█▁▂▃▄▅▆▇█
wandb:      test_acc_epoch ▁█▃▂▁█▁▇▁█
wandb:       test_acc_step ▃▆▂▃██▆█▅▄▅▂▆▄▂▄▄▄▄▅▇▇▆▇▁▅▄▅▆▆▇▇▂▂▄▁▇▇▇▄
wandb:     test_loss_epoch ▃▁▂█▂▁▃▂▂▁
wandb:      test_loss_step ▃▂▃▄▁▁▂▁▂▂▃▃▂▄█▇▃▂▂▂▁▂▄▂▄▂▂▂▃▂▂▁▃▃▂▃▁▂▂▄
wandb:     train_acc_epoch ▁▆▄▄▆▆▇▇▃▄▄▆▆▄▇▅▃▄▆▆▆█▇▆▃▄▆▆▆▆▅▅▄▅▅▅▅▆▇▆
wandb:      train_acc_step ▁▄▂▃▅▄▇▆▆▆▄▄▅▃▂▄▃▆▄▆▄▄▄▅▂▅▁▄▂▂▁▅▅▄▅▃█▄▂▃
wandb:    train_loss_epoch █▃▃▄▂▁▁▂█▅▄▄▂▄▂▃▇▄▂▃▂▁▂▁▆▅▃▂▃▂▁▃▆▃▃▂▂▂▁▂
wandb:     train_loss_step █▃▄▂▂▃▃▂▃▁▂▂▂▆▂▃▃▃▃▁▂▂▄▂▂▃▃▂▅▄▄▂▂▂▃▃▁▂▃▇
wandb: trainer/global_step ▁▁▁▂▂▂▂▃▁▁▁▂▂▂▂▃▁▁▁▂▂▂▂▃▁▁▃▂▂▂▃█▁▁▃▂▂▂▃▃
wandb: unbalanced accuracy ▁█▂▃▂█▁▇▃█
wandb:       val_acc_epoch ▂▃▆▅▇▇▆▇▄▆▇▅▆▅▇▆▅▇▆▄▇▇▆▆▆▇▇▆▅▁██▅▇▇▆▇█▅▆
wandb:        val_acc_step ▃▄▆▅▄▅▄▃▇▄▇▅▆▆▅▅▃▅▅▆▇▇▅▃▄▁▅▆▃█▅▁▅▆▄█▆▅▃▄
wandb:      val_loss_epoch █▅▂▂▂▂▄▁▄▅▁▂▂▂▂▂▃▁▂▄▁▂▃▂▂▂▁▂▃█▁▁▃▁▁▂▁▂▃▂
wandb:       val_loss_step ▅▅▂▅▄▂▆▆▂▆▁▂▃▂▂▃▃▄▅▃▂▁▃█▇▅▃▅▆▁▅█▃▄▅▃▃▂█▂
wandb: 
wandb: Run summary:
wandb:               epoch 0
wandb:      test_acc_epoch 0.81513
wandb:       test_acc_step 0.58333
wandb:     test_loss_epoch 0.96843
wandb:      test_loss_step 2.23892
wandb:     train_acc_epoch 0.57087
wandb:      train_acc_step 0.5
wandb:    train_loss_epoch 1.11311
wandb:     train_loss_step 2.29094
wandb: trainer/global_step 0
wandb: unbalanced accuracy 0.6975
wandb:       val_acc_epoch 0.49869
wandb:        val_acc_step 0.46154
wandb:      val_loss_epoch 1.53289
wandb:       val_loss_step 1.80915
wandb: 
wandb: Synced ADAM-pretrained-mara-on-isabel-fixingweights: https://wandb.ai/imenbm/Isabel_meerkat/runs/q7l0ain1
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230509_180054-q7l0ain1/logs
2023-05-09 18:16:15,261 INFO gridtk: Job 51 finished with result 0
